<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Optimized Camera OCR Scanner with Debugging</title>
    <!-- Tesseract.js CDN -->
    <script src="https://cdn.jsdelivr.net/npm/tesseract.js@v4.0.2/dist/tesseract.min.js"></script>
    <style>
        body, html {
            margin: 0;
            padding: 0;
            height: 100%;
            font-family: Arial, sans-serif;
            background-color: #f0f0f0;
        }
        #container {
            position: relative;
            width: 100%;
            height: 100%;
            overflow: hidden;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
        }
        video {
            width: 90%;
            max-width: 800px;
            border: 2px solid #333;
            border-radius: 8px;
            background-color: #000;
        }
        #overlay {
            position: absolute;
            width: 300px;
            height: 200px;
            border: 4px solid red;
            border-radius: 8px;
            pointer-events: none;
            transition: border-color 0.3s ease;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
        }
        #controls {
            margin-top: 20px;
            text-align: center;
        }
        #start-button, #stop-button {
            padding: 10px 20px;
            font-size: 16px;
            cursor: pointer;
            margin: 0 10px;
            border: none;
            border-radius: 4px;
        }
        #start-button {
            background-color: #28a745;
            color: #fff;
        }
        #start-button:disabled {
            background-color: #94d3a2;
            cursor: not-allowed;
        }
        #stop-button {
            background-color: #dc3545;
            color: #fff;
        }
        #stop-button:disabled {
            background-color: #e99a9f;
            cursor: not-allowed;
        }
        #output {
            margin-top: 20px;
            width: 90%;
            max-width: 800px;
            height: 150px;
            padding: 10px;
            border: 1px solid #ccc;
            border-radius: 4px;
            resize: none;
            font-size: 14px;
            overflow-y: auto;
            background-color: #fff;
        }
        #errorMsg {
            position: absolute;
            top: 10px;
            left: 50%;
            transform: translateX(-50%);
            background-color: rgba(255,0,0,0.9);
            color: #fff;
            padding: 10px 20px;
            border-radius: 4px;
            display: none;
            z-index: 10;
            font-weight: bold;
        }
        /* Debugging Canvas Styling */
        #debugCanvas {
            margin-top: 20px;
            border: 1px solid #000;
            display: none; /* Hide by default */
            max-width: 90%;
            height: auto;
        }
    </style>
</head>
<body>
    <div id="errorMsg"></div>
    <div id="container">
        <video id="video" autoplay playsinline></video>
        <div id="overlay"></div>
        <div id="controls">
            <button id="start-button">Start Scanner</button>
            <button id="stop-button" disabled>Stop Scanner</button>
            <textarea id="output" placeholder="Extracted text will appear here..." readonly></textarea>
        </div>
        <!-- Optional: Debugging Canvas -->
        <canvas id="debugCanvas"></canvas>
    </div>

    <script>
        // References to DOM elements
        const video = document.getElementById('video');
        const overlay = document.getElementById('overlay');
        const startButton = document.getElementById('start-button');
        const stopButton = document.getElementById('stop-button');
        const output = document.getElementById('output');
        const errorMsg = document.getElementById('errorMsg');
        const debugCanvas = document.getElementById('debugCanvas');

        let stream = null;
        let scanning = false;
        let lastScanTime = 0;
        const scanInterval = 2000; // Minimum interval between scans in ms

        // Function to display error messages
        function showError(message) {
            errorMsg.innerText = message;
            errorMsg.style.display = 'block';
            setTimeout(() => {
                errorMsg.style.display = 'none';
            }, 5000);
        }

        // Function to initialize camera
        async function initCamera() {
            try {
                stream = await navigator.mediaDevices.getUserMedia({
                    video: { facingMode: { exact: "environment" } },
                    audio: false
                });
                video.srcObject = stream;
            } catch (err) {
                console.error(err);
                showError('Unable to access the rear camera. Please check permissions or try a different device.');
            }
        }

        // Function to preprocess image for better OCR accuracy (Color-Based)
        function preprocessImage(videoCanvas, width, height) {
            const ctx = videoCanvas.getContext('2d');
            ctx.drawImage(video, 0, 0, width, height);

            // Get the image data from the canvas
            let imageData = ctx.getImageData(0, 0, width, height);
            let data = imageData.data;

            // Enhance contrast (simple contrast adjustment)
            const contrastFactor = 1.3; // Adjust as needed
            for (let i = 0; i < data.length; i += 4) {
                // Apply contrast formula
                data[i] = ((data[i] - 128) * contrastFactor) + 128;     // R
                data[i + 1] = ((data[i + 1] - 128) * contrastFactor) + 128; // G
                data[i + 2] = ((data[i + 2] - 128) * contrastFactor) + 128; // B
                // Clamp values to [0,255]
                data[i] = Math.min(255, Math.max(0, data[i]));
                data[i + 1] = Math.min(255, Math.max(0, data[i + 1]));
                data[i + 2] = Math.min(255, Math.max(0, data[i + 2]));
            }

            // Put the processed data back onto the canvas
            ctx.putImageData(imageData, 0, 0);
        }

        // Function to perform OCR
        async function performOCR(blob) {
            try {
                const { data: { text }, confidence } = await Tesseract.recognize(
                    blob,
                    'eng',
                    { 
                        logger: m => console.log(m),
                        tessedit_char_whitelist: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789.,/-()& ',
                        tessedit_pageseg_mode: Tesseract.PSM.SINGLE_BLOCK
                    }
                );

                console.log(`Confidence: ${confidence}`);
                console.log(`Extracted Text: "${text.trim()}"`);

                if (text.trim().length > 0) {
                    overlay.style.borderColor = 'green';
                    // Append the extracted text to the output field if not already present
                    if (!output.value.includes(text.trim())) {
                        output.value += text.trim() + '\n';
                    }
                } else {
                    overlay.style.borderColor = 'red';
                }
            } catch (err) {
                console.error('Tesseract.js error:', err);
                showError('An error occurred while processing the image.');
                overlay.style.borderColor = 'red';
            }
        }

        // Function to process frame
        async function processFrame() {
            const now = Date.now();
            if (now - lastScanTime < scanInterval) {
                requestAnimationFrame(processFrame);
                return;
            }
            lastScanTime = now;

            if (video.readyState !== video.HAVE_ENOUGH_DATA) {
                console.warn('Video not ready');
                requestAnimationFrame(processFrame);
                return;
            }

            // Set canvas dimensions to match video
            const videoWidth = video.videoWidth;
            const videoHeight = video.videoHeight;
            const videoCanvas = document.createElement('canvas');
            videoCanvas.width = videoWidth;
            videoCanvas.height = videoHeight;
            const videoCtx = videoCanvas.getContext('2d');

            // Preprocess the image (Color-Based)
            preprocessImage(videoCanvas, videoWidth, videoHeight);

            // Define ROI dimensions based on overlay position
            const overlayRect = overlay.getBoundingClientRect();
            const videoRect = video.getBoundingClientRect();

            // Calculate scaling factors between video display size and actual video size
            const scaleX = videoWidth / videoRect.width;
            const scaleY = videoHeight / videoRect.height;

            // Calculate ROI coordinates relative to the video
            const roiX = (overlayRect.left - videoRect.left) * scaleX;
            const roiY = (overlayRect.top - videoRect.top) * scaleY;
            const roiWidth = overlayRect.width * scaleX;
            const roiHeight = overlayRect.height * scaleY;

            // Ensure ROI is within the video frame
            if (roiX < 0 || roiY < 0 || (roiX + roiWidth) > videoWidth || (roiY + roiHeight) > videoHeight) {
                console.warn('ROI is out of video frame bounds.');
                showError('ROI is out of video frame bounds.');
                stopScanning();
                return;
            }

            // Extract ROI from the processed image
            const roiCanvas = document.createElement('canvas');
            roiCanvas.width = roiWidth;
            roiCanvas.height = roiHeight;
            const roiCtx = roiCanvas.getContext('2d');
            roiCtx.drawImage(videoCanvas, roiX, roiY, roiWidth, roiHeight, 0, 0, roiWidth, roiHeight);

            // Further preprocess ROI: scale up to improve OCR accuracy
            const scaleFactor = 2; // Reduced to 2 to balance performance and OCR accuracy
            const scaledCanvas = document.createElement('canvas');
            scaledCanvas.width = roiWidth * scaleFactor;
            scaledCanvas.height = roiHeight * scaleFactor;
            const scaledCtx = scaledCanvas.getContext('2d');
            scaledCtx.imageSmoothingEnabled = true;
            scaledCtx.imageSmoothingQuality = 'high';
            scaledCtx.drawImage(roiCanvas, 0, 0, scaledCanvas.width, scaledCanvas.height);

            // Update the debugging canvas efficiently
            debugCanvas.width = scaledCanvas.width;
            debugCanvas.height = scaledCanvas.height;
            const debugCtx = debugCanvas.getContext('2d');
            debugCtx.clearRect(0, 0, debugCanvas.width, debugCanvas.height);
            debugCtx.drawImage(scaledCanvas, 0, 0);
            debugCanvas.style.display = 'block'; // Make the debugging canvas visible

            // Convert the canvas to a blob for OCR
            scaledCanvas.toBlob(async (blob) => {
                if (blob) {
                    await performOCR(blob);
                }
                // Schedule the next frame processing
                requestAnimationFrame(processFrame);
            }, 'image/png');
        }

        // Function to start scanning
        function startScanning() {
            if (scanning) return;
            if (!stream) {
                showError('Camera not initialized.');
                return;
            }

            scanning = true;
            startButton.disabled = true;
            stopButton.disabled = false;
            startButton.innerText = 'Scanning...';
            output.value = ''; // Clear previous output

            requestAnimationFrame(processFrame);
        }

        // Function to stop scanning
        function stopScanning() {
            if (!scanning) return;

            scanning = false;
            startButton.disabled = false;
            stopButton.disabled = true;
            startButton.innerText = 'Start Scanner';
            lastScanTime = 0;
            // Optionally, clear the debugging canvas
            // const debugCtx = debugCanvas.getContext('2d');
            // debugCtx.clearRect(0, 0, debugCanvas.width, debugCanvas.height);
            // debugCanvas.style.display = 'none'; // Hide the debugging canvas
        }

        // Initialize camera on page load
        window.addEventListener('load', initCamera);

        // Handle start button click
        startButton.addEventListener('click', () => {
            startScanning();
        });

        // Handle stop button click
        stopButton.addEventListener('click', () => {
            stopScanning();
        });

        // Clean up on page unload
        window.addEventListener('beforeunload', () => {
            if (stream) {
                stream.getTracks().forEach(track => track.stop());
            }
        });
    </script>
</body>
</html>
