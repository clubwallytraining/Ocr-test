<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Reliable Camera OCR Scanner with Enhanced Filtering</title>
    <!-- Tesseract.js CDN -->
    <script src="https://cdn.jsdelivr.net/npm/tesseract.js@v4.0.2/dist/tesseract.min.js"></script>
    <style>
        /* [Existing CSS Styles] */
    </style>
</head>
<body>
    <div id="errorMsg"></div>
    <div id="container">
        <video id="video" autoplay playsinline></video>
        <div id="overlay"></div>
        <div id="controls">
            <button id="start-button">Start Scanner</button>
            <button id="stop-button" disabled>Stop Scanner</button>
            <textarea id="output" placeholder="Extracted text will appear here..." readonly></textarea>
        </div>
        <!-- Debugging Canvas -->
        <canvas id="debugCanvas"></canvas>
    </div>

    <script>
        // References to DOM elements
        const video = document.getElementById('video');
        const overlay = document.getElementById('overlay');
        const startButton = document.getElementById('start-button');
        const stopButton = document.getElementById('stop-button');
        const output = document.getElementById('output');
        const errorMsg = document.getElementById('errorMsg');
        const debugCanvas = document.getElementById('debugCanvas');

        let stream = null;
        let scanning = false;
        let lastScanTime = 0;
        const MIN_INTERVAL = 2000; // 2 seconds between scans
        const MIN_CONFIDENCE = 60; // Minimum confidence percentage to accept OCR result

        // Function to display error messages
        function showError(message) {
            console.log(`Error: ${message}`); // Log error to console
            errorMsg.innerText = message;
            errorMsg.style.display = 'block';
            setTimeout(() => {
                errorMsg.style.display = 'none';
            }, 5000);
        }

        // Function to initialize camera
        async function initCamera() {
            try {
                stream = await navigator.mediaDevices.getUserMedia({
                    video: { facingMode: { exact: "environment" } },
                    audio: false
                });
                video.srcObject = stream;
                console.log('Camera initialized successfully.');
            } catch (err) {
                console.error('Camera initialization failed:', err);
                showError('Unable to access the rear camera. Please check permissions or try a different device.');
            }
        }

        // Function to preprocess image for better OCR accuracy (Color-Based)
        function preprocessImage(videoCanvas, width, height) {
            const ctx = videoCanvas.getContext('2d');
            ctx.drawImage(video, 0, 0, width, height);
            console.log('Image drawn on videoCanvas.');

            // Get the image data from the canvas
            let imageData = ctx.getImageData(0, 0, width, height);
            let data = imageData.data;

            // Enhance contrast (simple contrast adjustment)
            const contrastFactor = 1.3; // Adjust as needed
            for (let i = 0; i < data.length; i += 4) {
                // Apply contrast formula
                data[i] = ((data[i] - 128) * contrastFactor) + 128;     // R
                data[i + 1] = ((data[i + 1] - 128) * contrastFactor) + 128; // G
                data[i + 2] = ((data[i + 2] - 128) * contrastFactor) + 128; // B
                // Clamp values to [0,255]
                data[i] = Math.min(255, Math.max(0, data[i]));
                data[i + 1] = Math.min(255, Math.max(0, data[i + 1]));
                data[i + 2] = Math.min(255, Math.max(0, data[i + 2]));
            }

            // Put the processed data back onto the canvas
            ctx.putImageData(imageData, 0, 0);
            console.log('Image preprocessing complete.');
        }

        // Function to perform OCR
        async function performOCR(blob) {
            console.log('Starting OCR process.');
            try {
                const { data: { text }, confidence } = await Tesseract.recognize(
                    blob,
                    'eng',
                    { 
                        logger: m => console.log(m),
                        tessedit_char_whitelist: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789.,/-()& ',
                        tessedit_pageseg_mode: Tesseract.PSM.SINGLE_BLOCK
                    }
                );

                console.log(`OCR Confidence: ${confidence}`);
                console.log(`OCR Extracted Text: "${text.trim()}"`);

                if (confidence >= MIN_CONFIDENCE && text.trim().length > 0) {
                    overlay.style.borderColor = 'green';
                    // Append the extracted text to the output field if not already present
                    if (!output.value.includes(text.trim())) {
                        output.value += text.trim() + '\n';
                        console.log('Text appended to output.');
                    }
                } else {
                    overlay.style.borderColor = 'red';
                    console.log('OCR confidence too low or no text detected.');
                }
            } catch (err) {
                console.error('Tesseract.js error:', err);
                showError('An error occurred while processing the image.');
                overlay.style.borderColor = 'red';
            }
        }

        // Function to process frame
        async function processFrame() {
            const now = Date.now();
            if (now - lastScanTime < MIN_INTERVAL) {
                // Skip processing if within the interval
                requestAnimationFrame(processFrame);
                return;
            }
            lastScanTime = now;

            if (video.readyState !== video.HAVE_ENOUGH_DATA) {
                console.warn('Video not ready');
                requestAnimationFrame(processFrame);
                return;
            }

            console.log('Processing a new frame for OCR.');

            // Set canvas dimensions to match video
            const videoWidth = video.videoWidth;
            const videoHeight = video.videoHeight;
            const videoCanvas = document.createElement('canvas');
            videoCanvas.width = videoWidth;
            videoCanvas.height = videoHeight;
            const videoCtx = videoCanvas.getContext('2d');

            // Preprocess the image (Color-Based)
            preprocessImage(videoCanvas, videoWidth, videoHeight);

            // Define ROI dimensions based on overlay position
            const overlayRect = overlay.getBoundingClientRect();
            const videoRect = video.getBoundingClientRect();

            // Calculate scaling factors between video display size and actual video size
            const scaleX = videoWidth / videoRect.width;
            const scaleY = videoHeight / videoRect.height;

            // Calculate ROI coordinates relative to the video
            const roiX = (overlayRect.left - videoRect.left) * scaleX;
            const roiY = (overlayRect.top - videoRect.top) * scaleY;
            const roiWidth = overlayRect.width * scaleX;
            const roiHeight = overlayRect.height * scaleY;

            console.log(`ROI Coordinates: (${roiX}, ${roiY}, ${roiWidth}, ${roiHeight})`);

            // Ensure ROI is within the video frame
            if (roiX < 0 || roiY < 0 || (roiX + roiWidth) > videoWidth || (roiY + roiHeight) > videoHeight) {
                console.warn('ROI is out of video frame bounds.');
                showError('ROI is out of video frame bounds.');
                stopScanning();
                return;
            }

            // Extract ROI from the processed image
            const roiCanvas = document.createElement('canvas');
            roiCanvas.width = roiWidth;
            roiCanvas.height = roiHeight;
            const roiCtx = roiCanvas.getContext('2d');
            roiCtx.drawImage(videoCanvas, roiX, roiY, roiWidth, roiHeight, 0, 0, roiWidth, roiHeight);
            console.log('ROI extracted.');

            // Further preprocess ROI: scale up to improve OCR accuracy
            const scaleFactor = 2; // Adjust as needed
            const scaledCanvas = document.createElement('canvas');
            scaledCanvas.width = roiWidth * scaleFactor;
            scaledCanvas.height = roiHeight * scaleFactor;
            const scaledCtx = scaledCanvas.getContext('2d');
            scaledCtx.imageSmoothingEnabled = true;
            scaledCtx.imageSmoothingQuality = 'high';
            scaledCtx.drawImage(roiCanvas, 0, 0, scaledCanvas.width, scaledCanvas.height);
            console.log('ROI scaled.');

            // Update the debugging canvas
            debugCanvas.width = scaledCanvas.width;
            debugCanvas.height = scaledCanvas.height;
            const debugCtx = debugCanvas.getContext('2d');
            debugCtx.clearRect(0, 0, debugCanvas.width, debugCanvas.height);
            debugCtx.drawImage(scaledCanvas, 0, 0);
            console.log('Debugging canvas updated.');

            // Convert the canvas to a blob for OCR
            scaledCanvas.toBlob(async (blob) => {
                if (blob) {
                    console.log('Blob created for OCR.');
                    await performOCR(blob);
                } else {
                    console.warn('Blob conversion failed.');
                }
                // Schedule the next frame processing
                requestAnimationFrame(processFrame);
            }, 'image/png');
        }

        // Function to start scanning
        function startScanning() {
            if (scanning) return;
            if (!stream) {
                showError('Camera not initialized.');
                return;
            }

            scanning = true;
            startButton.disabled = true;
            stopButton.disabled = false;
            startButton.innerText = 'Scanning...';
            output.value = ''; // Clear previous output
            console.log('Scanning started.');

            requestAnimationFrame(processFrame);
        }

        // Function to stop scanning
        function stopScanning() {
            if (!scanning) return;

            scanning = false;
            startButton.disabled = false;
            stopButton.disabled = true;
            startButton.innerText = 'Start Scanner';
            lastScanTime = 0;
            console.log('Scanning stopped.');

            // Optionally, clear the debugging canvas
            // const debugCtx = debugCanvas.getContext('2d');
            // debugCtx.clearRect(0, 0, debugCanvas.width, debugCanvas.height);
            // debugCanvas.style.display = 'none'; // Hide the debugging canvas
        }

        // Initialize camera on page load
        window.addEventListener('load', initCamera);

        // Handle start button click
        startButton.addEventListener('click', () => {
            startScanning();
        });

        // Handle stop button click
        stopButton.addEventListener('click', () => {
            stopScanning();
        });

        // Clean up on page unload
        window.addEventListener('beforeunload', () => {
            if (stream) {
                stream.getTracks().forEach(track => track.stop());
            }
        });
    </script>
</body>
</html>
