<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>High-Accuracy Camera OCR Scanner</title>
    <!-- Tesseract.js CDN -->
    <script src="https://cdn.jsdelivr.net/npm/tesseract.js@v4.0.2/dist/tesseract.min.js"></script>
    <style>
        body, html {
            margin: 0;
            padding: 0;
            height: 100%;
            font-family: Arial, sans-serif;
            background-color: #f0f0f0;
        }
        #container {
            position: relative;
            width: 100%;
            height: 100%;
            overflow: hidden;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
        }
        video {
            width: 100%;
            height: auto;
            max-height: 80vh;
            background-color: #000;
        }
        #overlay {
            position: absolute;
            top: 50%;
            left: 50%;
            width: 300px;
            height: 200px;
            transform: translate(-50%, -50%);
            border: 4px solid red;
            box-sizing: border-box;
            pointer-events: none;
            transition: border-color 0.3s ease;
        }
        #controls {
            margin-top: 20px;
            text-align: center;
        }
        #start-button, #stop-button {
            padding: 10px 20px;
            font-size: 16px;
            cursor: pointer;
            margin: 0 10px;
        }
        #stop-button:disabled {
            background-color: #ccc;
            cursor: not-allowed;
        }
        #output {
            margin-top: 20px;
            width: 80%;
            max-width: 600px;
            height: 150px;
            padding: 10px;
            border: 1px solid #ccc;
            resize: none;
            font-size: 14px;
            overflow-y: auto;
        }
        #errorMsg {
            position: absolute;
            top: 10px;
            left: 50%;
            transform: translateX(-50%);
            background-color: rgba(255,0,0,0.8);
            color: #fff;
            padding: 10px 20px;
            border-radius: 4px;
            display: none;
            z-index: 10;
        }
        /* Styling for debugging canvas */
        #debugCanvas {
            margin-top: 20px;
            border: 1px solid #000;
            display: none; /* Initially hidden */
        }
    </style>
</head>
<body>
    <div id="errorMsg"></div>
    <div id="container">
        <video id="video" autoplay playsinline></video>
        <div id="overlay"></div>
        <div id="controls">
            <button id="start-button">Start Scanner</button>
            <button id="stop-button" disabled>Stop Scanner</button>
            <textarea id="output" placeholder="Extracted text will appear here..." readonly></textarea>
        </div>
        <!-- Debugging Canvas -->
        <canvas id="debugCanvas"></canvas>
    </div>

    <script>
        // References to DOM elements
        const video = document.getElementById('video');
        const overlay = document.getElementById('overlay');
        const startButton = document.getElementById('start-button');
        const stopButton = document.getElementById('stop-button');
        const output = document.getElementById('output');
        const errorMsg = document.getElementById('errorMsg');
        const debugCanvas = document.getElementById('debugCanvas');

        let stream = null;
        let scanning = false;
        let scanInterval = null;

        // Function to display error messages
        function showError(message) {
            errorMsg.innerText = message;
            errorMsg.style.display = 'block';
            setTimeout(() => {
                errorMsg.style.display = 'none';
            }, 5000);
        }

        // Function to initialize camera
        async function initCamera() {
            try {
                stream = await navigator.mediaDevices.getUserMedia({
                    video: { facingMode: { exact: "environment" } },
                    audio: false
                });
                video.srcObject = stream;
            } catch (err) {
                console.error(err);
                showError('Unable to access the rear camera. Please check permissions or try a different device.');
            }
        }

        // Function to preprocess image for better OCR accuracy
        function preprocessImage(canvas, ctx, width, height) {
            // Draw the current frame onto the canvas
            ctx.drawImage(video, 0, 0, width, height);

            // Get the image data from the canvas
            let imageData = ctx.getImageData(0, 0, width, height);
            let data = imageData.data;

            // Convert to grayscale
            for (let i = 0; i < data.length; i += 4) {
                let avg = (data[i] + data[i + 1] + data[i + 2]) / 3;
                data[i] = data[i + 1] = data[i + 2] = avg;
            }

            // Apply adaptive thresholding
            // Using a simple local average for adaptive threshold
            const region = 15; // Size of the region for local average
            for (let y = 0; y < height; y++) {
                for (let x = 0; x < width; x++) {
                    let index = (y * width + x) * 4;
                    let sum = 0;
                    let count = 0;
                    for (let dy = -Math.floor(region/2); dy <= Math.floor(region/2); dy++) {
                        for (let dx = -Math.floor(region/2); dx <= Math.floor(region/2); dx++) {
                            let nx = x + dx;
                            let ny = y + dy;
                            if (nx >=0 && nx < width && ny >=0 && ny < height) {
                                let nIndex = (ny * width + nx) * 4;
                                sum += data[nIndex];
                                count++;
                            }
                        }
                    }
                    let localAvg = sum / count;
                    let value = data[index] > localAvg ? 255 : 0;
                    data[index] = data[index + 1] = data[index + 2] = value;
                }
            }

            // Put the processed data back onto the canvas
            ctx.putImageData(imageData, 0, 0);
        }

        // Function to start scanning
        function startScanning() {
            if (scanning) return;
            if (!stream) {
                showError('Camera not initialized.');
                return;
            }

            scanning = true;
            startButton.disabled = true;
            stopButton.disabled = false;
            startButton.innerText = 'Scanning...';
            output.value = ''; // Clear previous output

            const canvas = document.createElement('canvas');
            const ctx = canvas.getContext('2d');

            scanInterval = setInterval(async () => {
                if (video.readyState !== video.HAVE_ENOUGH_DATA) {
                    console.warn('Video not ready');
                    return;
                }

                // Set canvas dimensions to match video
                const videoWidth = video.videoWidth;
                const videoHeight = video.videoHeight;
                canvas.width = videoWidth;
                canvas.height = videoHeight;

                // Preprocess the image
                preprocessImage(canvas, ctx, videoWidth, videoHeight);

                // Define ROI dimensions based on overlay position
                const overlayRect = overlay.getBoundingClientRect();
                const videoRect = video.getBoundingClientRect();

                // Calculate scaling factors between video display size and actual video size
                const scaleX = videoWidth / videoRect.width;
                const scaleY = videoHeight / videoRect.height;

                // Calculate ROI coordinates relative to the video
                const roiX = (overlayRect.left - videoRect.left) * scaleX;
                const roiY = (overlayRect.top - videoRect.top) * scaleY;
                const roiWidth = overlayRect.width * scaleX;
                const roiHeight = overlayRect.height * scaleY;

                // Ensure ROI is within the video frame
                if (roiX < 0 || roiY < 0 || (roiX + roiWidth) > videoWidth || (roiY + roiHeight) > videoHeight) {
                    console.warn('ROI is out of video frame bounds.');
                    showError('ROI is out of video frame bounds.');
                    stopScanning();
                    return;
                }

                // Extract ROI from the processed image
                let roiCanvas = document.createElement('canvas');
                roiCanvas.width = roiWidth;
                roiCanvas.height = roiHeight;
                let roiCtx = roiCanvas.getContext('2d');
                roiCtx.drawImage(canvas, roiX, roiY, roiWidth, roiHeight, 0, 0, roiWidth, roiHeight);

                // Further preprocess ROI: scale up to improve OCR accuracy
                const scaleFactor = 3; // Adjust as needed
                let scaledCanvas = document.createElement('canvas');
                scaledCanvas.width = roiWidth * scaleFactor;
                scaledCanvas.height = roiHeight * scaleFactor;
                let scaledCtx = scaledCanvas.getContext('2d');
                scaledCtx.imageSmoothingEnabled = true;
                scaledCtx.imageSmoothingQuality = 'high';
                scaledCtx.drawImage(roiCanvas, 0, 0, scaledCanvas.width, scaledCanvas.height);

                // Display the ROI on the debugging canvas for verification
                debugCanvas.width = scaledCanvas.width;
                debugCanvas.height = scaledCanvas.height;
                let debugCtx = debugCanvas.getContext('2d');
                debugCtx.clearRect(0, 0, debugCanvas.width, debugCanvas.height);
                debugCtx.drawImage(scaledCanvas, 0, 0);
                debugCanvas.style.display = 'block'; // Make the debugging canvas visible

                // Convert the canvas to a blob for OCR
                scaledCanvas.toBlob(async (blob) => {
                    if (blob) {
                        try {
                            const { data: { text }, confidence } = await Tesseract.recognize(
                                blob,
                                'eng',
                                { 
                                    logger: m => console.log(m),
                                    tessedit_char_whitelist: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789.,/-()& ',
                                }
                            );

                            console.log(`Confidence: ${confidence}`);
                            console.log(`Extracted Text: "${text.trim()}"`);

                            if (text.trim().length > 0) {
                                overlay.style.borderColor = 'green';
                                // Append the extracted text to the output field if not already present
                                if (!output.value.includes(text.trim())) {
                                    output.value += text.trim() + '\n';
                                }
                            } else {
                                overlay.style.borderColor = 'red';
                                // Optionally, notify the user or take other actions
                                // output.value = 'No text detected.';
                            }
                        } catch (err) {
                            console.error('Tesseract.js error:', err);
                            showError('An error occurred while processing the image.');
                            overlay.style.borderColor = 'red';
                        }
                    }
                }, 'image/png');
            }, 1000); // Scan every 1 second
        }

        // Function to stop scanning
        function stopScanning() {
            if (!scanning) return;

            scanning = false;
            startButton.disabled = false;
            stopButton.disabled = true;
            startButton.innerText = 'Start Scanner';
            clearInterval(scanInterval);
            overlay.style.borderColor = 'red';
            debugCanvas.style.display = 'none'; // Hide the debugging canvas
        }

        // Initialize camera on page load
        window.addEventListener('load', initCamera);

        // Handle start button click
        startButton.addEventListener('click', () => {
            startScanning();
        });

        // Handle stop button click
        stopButton.addEventListener('click', () => {
            stopScanning();
        });

        // Clean up on page unload
        window.addEventListener('beforeunload', () => {
            if (stream) {
                stream.getTracks().forEach(track => track.stop());
            }
            clearInterval(scanInterval);
        });
    </script>
</body>
</html>
